{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to classification\n",
    "\n",
    "<img src=\"https://www.mrtfuelcell.polimi.it/images/logo_poli.jpg\" height=\"200\">\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg\" height=\"150\">\n",
    "\n",
    "A2A ML Course - day 5 - 31/10/2024\n",
    "\n",
    "Maciej Sakwa, Micheal Wood, Emanuele Ogliari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. Machine Learning Project Structure (review)\n",
    "2. Logistic Regression\n",
    "3. Evaluation metrics in classification\n",
    "4. Case study (EV data + multiclass classification)\n",
    "\n",
    "## Learning obejctives\n",
    "\n",
    "* Understand the logistic function and its use in classification problems\n",
    "* Define typical metrics used to describe classification problems (accuracy, precision, recall)\n",
    "* Understand the differences in approach between binary and multiple choice problems\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please run the cells below with imports and function declarations** \n",
    "\n",
    "Feel free to skip the details of the content.\n",
    "\n",
    "---\n",
    "\n",
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.display.float_format = '{:.2f}'.format # print 2 decimal places\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(filepath):\n",
    "    df = pd.read_csv(filepath,index_col='time',)\n",
    "    df.index = pd.to_datetime(df.index,utc=True,format='ISO8601')\n",
    "    df.index = df.index.tz_convert('Europe/Madrid').tz_localize(None)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(data):\n",
    "\n",
    "    zeros_list = [\n",
    "        'generation fossil coal-derived gas',\n",
    "        'generation fossil oil shale',\n",
    "        'generation fossil peat',\n",
    "        'generation geothermal',\n",
    "        'generation marine',\n",
    "        'generation wind offshore',\n",
    "        'generation hydro pumped storage aggregated',\n",
    "        'forecast wind offshore eday ahead']\n",
    "    nonzeros_list = [x for x in data.columns if x not in zeros_list]\n",
    "\n",
    "    generations_list = [x for x in nonzeros_list if x.startswith('generation')]\n",
    "\n",
    "    data = data[generations_list]\n",
    "\n",
    "    return data.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maths functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def log_loss(labels, probas):\n",
    "    \n",
    "    log_probas = np.log([probas[i] if labels[i] == 1 else (1-probas[i]) for i in range(len(probas))])\n",
    "    loss = sum(log_probas)\n",
    "\n",
    "    return np.mean(-loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(data, x_col='generation fossil hard coal', y_col='generation wind onshore', w=None, b=None, GoF=False):\n",
    "\n",
    "    groups = data.groupby('label')\n",
    "    for name, group in groups: \n",
    "        plt.scatter(x=group[x_col], y=group[y_col], label=f'Label: {name}')\n",
    "    plt.xlabel('Generation Coal (GW) - x')\n",
    "    plt.ylabel('Generation Wind (GW) - y')\n",
    "\n",
    "    if w is not None:\n",
    "        x = np.linspace(data[x_col].min(), data[x_col].max(), 100)\n",
    "        y = w * x + b\n",
    "        plt.plot(x, y, linestyle='--', c='r', label='Division boundary')\n",
    "\n",
    "    if GoF:\n",
    "        est = (data[y_col] - (w * data[x_col] + b)) / data[y_col].std()\n",
    "        probas = logit(est)\n",
    "        loss = log_loss(data['label'], probas)\n",
    "        plt.title(f'Log loss: {loss:.2f}')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_logit(data=None, x_col=None, y_col=None, threshold=None, mark_classes=False, **kwargs): # you don't have to understand this code\n",
    "\n",
    "    x = np.linspace(-6, 6, 1000)\n",
    "    colors = ['teal', 'orange']\n",
    "\n",
    "    plt.figure(**kwargs)\n",
    "    plt.axhline(0, c='k', linestyle = ':', alpha = 0.5, linewidth=1)\n",
    "    plt.axhline(1, c='k', linestyle = ':', alpha = 0.5, linewidth=1)\n",
    "    plt.axvline(0, c='k', linewidth=1, alpha = 0.5)\n",
    "    plt.plot(x, logit(x), c = 'grey')\n",
    "    plt.title('Logistic function')\n",
    "    plt.xlabel('Estimate value')\n",
    "    plt.ylabel('Logit value')\n",
    "\n",
    "    if data is not None:\n",
    "        if mark_classes:\n",
    "            groups = data.groupby('label')\n",
    "            for i, group in enumerate(groups):\n",
    "                name, df = group\n",
    "                plt.scatter(df[x_col], df[y_col], label = f'Class: {name}', c=colors[i], zorder=3, alpha=0.5)\n",
    "        else:\n",
    "            plt.scatter(data[x_col], data[y_col], c='r', zorder=3)\n",
    "\n",
    "    if threshold is not None:\n",
    "        data['pred'] = [1 if x >= threshold else 0 for x in data[y_col]]\n",
    "        groups = data.groupby('pred')\n",
    "        for i, group in enumerate(groups):\n",
    "            name, df = group\n",
    "            plt.scatter(df[x_col], df['pred'], c=colors[i], zorder=3, marker='x', label=f'Pred Class: {name}')\n",
    "            for i, row in df.iterrows():\n",
    "                x = row[x_col]\n",
    "                y_1, y_2 = (row[y_col], row['pred'])\n",
    "                plt.plot([x, x], [y_1, y_2], c='grey', linewidth=0.5, linestyle='--')\n",
    "        plt.axhline(threshold, c='red', linestyle='--', linewidth=1, label='Threshold')\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did you run all the cells?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data - it's the same dataset as before. Now we will focus a bit more on the different generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = import_data('https://raw.githubusercontent.com/woodjmichael/Basi-Fondamentali-del-Machine-Learning/refs/heads/main/data/energy_supply.csv')\n",
    "data = preprocess_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data does not have a categorical label. Let's cheat a bit and add our own label\n",
    "\n",
    "It is based on the share of renewables production in a given hour \n",
    "\n",
    "1 if the share is above 50%, 0 if it's below 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewables_list = [\n",
    "    'generation other renewable',\n",
    "    'generation solar', \n",
    "    'generation hydro water reservoir', \n",
    "    'generation hydro run-of-river and poundage', \n",
    "    'generation biomass',\n",
    "    'generation wind onshore',\n",
    "    'generation hydro pumped storage consumption',\n",
    "    ]\n",
    "\n",
    "data['renewables share'] = data[renewables_list].sum(axis=1)  / data.sum(axis=1)\n",
    "data['label'] = [1 if i >= 0.5 else 0 for i in data['renewables share']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the label and share:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['renewables share','label']][:36].plot()\n",
    "plt.axhline(0.5, c='k', linestyle=':', label='cutoff');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM DEFINITION:** Detect the class (renewable majority or minority in share) based on variables form the dataset. \n",
    "\n",
    "|I/O|  Data |\n",
    "| --- | --- |\n",
    "|Inputs| `generation fossil coal hard`, `generation wind onshore`, etc |\n",
    "|Target|  `label` |\n",
    "|Output| `label estimate` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try approaching the topic as we did before:\n",
    "\n",
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split inputs and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = data.columns.to_list() \n",
    "input_columns.remove('label')\n",
    "\n",
    "inputs = data[input_columns].copy()\n",
    "labels = data[['label']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() \n",
    "\n",
    "inputs_scaled = scaler.fit_transform(inputs) \n",
    "labels_scaled = labels.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide in train and test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(inputs) \n",
    "cutoff = int(0.7*n) # Train on 70% of the data, test on 30%\n",
    "\n",
    "train_inputs = inputs_scaled[:cutoff]   # Cut before\n",
    "train_labels = labels_scaled[:cutoff]   # Cut before\n",
    "\n",
    "test_inputs = inputs_scaled[cutoff:]    # Cut after\n",
    "test_labels = labels_scaled[cutoff:]    # Cut after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare and fit the linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X=train_inputs, y=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Plots\n",
    "plt.plot(test_labels, label='Price Actual')\n",
    "plt.plot(results, label='Price Actual Estimated')\n",
    "\n",
    "# Visuals\n",
    "plt.xlim((0,520))\n",
    "plt.xlabel('Test sample')\n",
    "plt.ylabel('Price (â‚¬/MW)')\n",
    "plt.grid(which='major', alpha = 0.5)\n",
    "\n",
    "# Tidy up\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's garbage! \n",
    "\n",
    "In this case we are going to skip the evaluation of the results, as it is obvious we are not going to do right.\n",
    "\n",
    "Besides, for classification we will have to define new metrics that better fit the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "As we are not predicting an exact value a traditional linear regression is useless.\n",
    "\n",
    "We have to create a function that outputs values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression - \"by hand\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In standard linear regression our output was defined with an equation $ w \\cdot X + b = \\hat{y} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a 2D case with 2 columns of data for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['generation fossil hard coal', 'generation wind onshore', 'label']][0:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise it on a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instances are collored according to the label that we defeined before, orange means high renewable share, blue the opposite.\n",
    "\n",
    "What is interesting is that we can easily *see* the division between the groups.\n",
    "\n",
    "In fact, let's try to draw a line between the groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 3\n",
    "b = 1000\n",
    "\n",
    "plot_scatter(X, w=w, b=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can \"estimate\" the class by deciding if the point is above or below our line. If it's above it's positive, otherwise negative.\n",
    "\n",
    "We can do it by simply substracting the line y-value from the point y-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['estimate'] = (X['generation wind onshore'] - (w * X['generation fossil hard coal'] + b))     # Subtract the line value\n",
    "X['estimate'] = X['estimate'] / (X['generation wind onshore'].std())                            # Standardize by dividing by the standard deviation of y (just for better scale)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ended up with a bunch of positive and negative values specified for the points in our dataset. We have to convert them somehow into classes.\n",
    "\n",
    "So what we really have to do is to impose a function $\\sigma$ on our results, that flattens it at the ends to 0 and 1.\n",
    "\n",
    "$$ \\sigma(\\hat{y}) = \\sigma(w \\cdot X + b) $$\n",
    "\n",
    "where $\\sigma$ is our flattening function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer to that is the **logistic function** (also called a **log**istic un**it** or **logit** for short):\n",
    "\n",
    "$$\n",
    "\\sigma(\\hat{y}) = \\frac{1}{1 - \\exp(-(w \\cdot X + b))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the logit function run the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_logit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may remember it from the previous lesson :)\n",
    "\n",
    "Let's apply it to our estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['logit estimate'] = logit(X['estimate'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_logit(X, x_col='estimate', y_col='logit estimate') # Put mark_classes = True to see the true class of each point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the logistic function is not really the binary 0-1 label. It is a value in the 0-1 range.\n",
    "\n",
    "We say that the output of a logistic function is the estimated **probability** that an inputs belongs to the 1 class.\n",
    "\n",
    "$\n",
    "    \\hat{p} = \\sigma(\\hat{y}) \n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the first point at 2015-01-01 00:00:00 has a **3% probability** of being the member of **class 1**.\n",
    "\n",
    "So probably, it is not the member of **class 1**. But what if it was **60%**? Does it belong to **class 1** or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What % is the cutoff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_threshold = 0.5  # Try to change the threshold a bit to see how it changes\n",
    "\n",
    "# PLot the logit\n",
    "plot_logit(X, x_col='estimate', y_col='logit estimate', mark_classes=True, threshold=selected_threshold, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['pred'] = [1 if est >= selected_threshold else 0 for est in X['logit estimate']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And there we go!** The instances are divided into separate binary classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of fit\n",
    "\n",
    "Now, we have to specify the *goodness of fit* metric for the algorithm to minimize (similarly to the squares in regression). In case of classification it is called the **Log-Loss** or **the Cross-Entropy**:\n",
    "\n",
    "$\n",
    "    L_{log}(y, p) = -(y_1 \\log(p_1) + (1-y_0) \\log(1-p_0)) \n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(probas=X['logit estimate'], labels=X['label'])  # It's the original label, not the prediction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you tune the *w* and *b* parameters to minimize the loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 2\n",
    "b = 2000\n",
    "\n",
    "plot_scatter(X, w=w, b=b, GoF=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any new entries (e.g. the test data), we can just calculate the fitted function and its logit to estimate the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics in classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, with classification we are dealing with **categories** and **probabilities** instead of real values\n",
    "\n",
    "So we can't use the same metrics to evaluate our model\n",
    "\n",
    "*no MAE, no MSE, no RMSE, no MAPE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we base our evaluation on a **CONFUSION MATRIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(X['label'], X['pred'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** - percentage of correctly identified classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (33 + 75) / (33 + 1 + 11 + 75)\n",
    "\n",
    "print(f'Global accuracy: {a:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** - the cleanliness of predicted classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_0 = 33 / (11 + 33)\n",
    "p_1 = 75 / (1 + 75)\n",
    "\n",
    "print(f'Precision: \\n -Class 0: {p_0:.2f}\\n -Class 1: {p_1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** - the capture rate of true class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_0 = 33 / (33 + 1)\n",
    "r_1 = 75 / (11 + 75)\n",
    "\n",
    "print(f'Recall: \\n -Class 0: {r_0:.2f}\\n -Class 1: {r_1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 - score** - combines the precision and recall. Favors similar values of the two (not always good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_0 = 2 * p_0 * r_0 / (p_0 + r_0)\n",
    "f1_1 = 2 * p_1 * r_1 / (p_1 + r_1)\n",
    "\n",
    "print(f'F1: \\n -Class 0: {f1_0:.2f}\\n -Class 1: {f1_1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision recall tradeoff\n",
    "\n",
    "The values of precision and recall depend on our model's and the selected threshold.\n",
    "\n",
    "Unfortunately, we can't increase the **precision** and **recall** at the same time. \n",
    "\n",
    "The more we increse the cleanliness of our group (precision grows), the more the capture rate (recall) drops. \n",
    "\n",
    "We can easily visualise it on the logit plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_threshold = 0.50\n",
    "\n",
    "# PLot the logit\n",
    "plot_logit(X, x_col='estimate', y_col='logit estimate', mark_classes=True, threshold=selected_threshold, figsize=(10, 6))\n",
    "\n",
    "#plt.xlim(-0.7, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact we can calculate the precision and recall for many different thresholds, and plot the dependence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(X['label'], X['logit estimate'])\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the trade-off between the precision and recall at various thresholds and is often called the **precision-recall-curve**\n",
    "\n",
    "It is often used to compare classifiers performance on the same dataset.\n",
    "\n",
    "For **a perfect classifier** the curve is almost a square (as in our very simple example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem definition\n",
    "\n",
    "<img src=\"https://www.mrtfuelcell.polimi.it/images/logo_poli.jpg\" height=\"200\">\n",
    "<img src=\"https://logowik.com/content/uploads/images/technischen-universitat-berlin1469.jpg\" height=\"200\">\n",
    "\n",
    "\n",
    "The dataset that we are going to be using comes from a detailed recording of LG Li-ion batteries performed jointly by PoliMi and TUB. It is composed of discharge data of multiple battery cells at different driving cycles (LA92, US06, ect.) and various temperatures ranging from negative 25 to positive 35.\n",
    "\n",
    "The dataset has been pubiled in open access and can be accessed [here](https://data.mendeley.com/datasets/6hyhsjbwkb/1)\n",
    "\n",
    "In this case study we will use a small snippet of the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Estimate the battery State-of-Charge (high, medium, low) based on simple parameters (I, V, T)**\n",
    "\n",
    "|I/O|  Data |\n",
    "| --- | --- |\n",
    "|Inputs| `I`, `V`, `T` |\n",
    "|Target|  `label` (High, Medium, Low)|\n",
    "|Output| `label estimate` (High, Medium, Low)|\n",
    "\n",
    "In our dataset we have the actual SoC, however for a simple classification problem we will convert it into 3 classes - High - Medium - Low charge (for splits 100% - 75% - 25%- 0% accordingly).\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/woodjmichael/Basi-Fondamentali-del-Machine-Learning/refs/heads/main/images/battery_class.png' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data introduction and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our data and see it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bat = pd.read_csv('https://raw.githubusercontent.com/woodjmichael/Basi-Fondamentali-del-Machine-Learning/refs/heads/main/data/battery_data.csv') # Replace url\n",
    "data_bat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been already preprocessed so we do not have to worry about cleaning or scaling. \n",
    "\n",
    "All features range from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give a look at the driving cycles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=data_bat, y='SoC', width=1000, height=600) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the label column based on the SoC value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bat['label'] = ['high' if soc > 0.75 else 'low' if soc < 0.25 else 'medium' for soc in data_bat['SoC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the driving cycles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_frame=data_bat, y='SoC', color='label', width=1000, height=600) # Replace 'SoC' with 'V', 'T', or 'I' to see other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it in 2D a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_frame=data_bat, x='T', y='SoC', color='label', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot it in 3D as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(data_frame=data_bat, x='V', y='I', z='T', color='label', width=1000, height=600)\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=20, b=20),)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check out the final table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant difference between our previous case study and the new one: **we have 1 more class**\n",
    "\n",
    "The problem changes from binary to multiclass classification\n",
    "\n",
    "Yet our **Logistic model** supports only two classes: 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_logit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we change to the multiclass case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ONE vs ALL classifiers**\n",
    "\n",
    "The first answer is simple: we train multiple one vs others classifiers that are able to predict a single class.\n",
    "\n",
    "We aggregate the results afterwards:\n",
    "\n",
    "\n",
    "<img src='https://amueller.github.io/aml/_images/ovr_lines.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Extract data\n",
    "X = data_bat[['I', 'V', 'T']].copy()\n",
    "y = data_bat['label'].copy()\n",
    "\n",
    "# Encode our labels as 0, 1, 2 instead of text\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "# Declare the model\n",
    "logr = LogisticRegression(multi_class='ovr') # OvR training\n",
    "logr.fit(X_train, y_train)\n",
    "\n",
    "# Run predictions\n",
    "y_probas = logr.predict_proba(X_test)\n",
    "y_preds = np.argmax(y_probas, axis=1)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_pred=y_preds, y_true=y_test)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=enc.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Model details\n",
    "print(f'Logistic regression features: {logr.n_features_in_}')\n",
    "print(f'Logistic regression iterations: {logr.n_iter_}')\n",
    "\n",
    "# Display results\n",
    "df_y = pd.DataFrame(data=y_test)\n",
    "print(f'---\\nClass population: \\n{df_y.value_counts()}')\n",
    "print(f'---\\nGlobal accuracy: {accuracy_score(y_test, y_preds):.2f}')\n",
    "print(f'---\\nClasses: {enc.classes_}')\n",
    "print(f'Precision: {precision_score(y_test, y_preds, average=None)}')\n",
    "print(f'Recall: {recall_score(y_test, y_preds, average=None)}')\n",
    "print(f'F1 score: {f1_score(y_test, y_preds, average=None)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works fine, but only because our model is small.\n",
    "\n",
    "What if the model is huge and we can't afford to train it multiple times?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOFTMAX function**\n",
    "\n",
    "Softmax function or the Multinomial Logistic Regression is a common solution for robust classification models (e.g. big image classifiers) when we cannot afford to train the model multiple times for **OvR** predictions.\n",
    "\n",
    "<img src='https://images.contentstack.io/v3/assets/bltac01ee6daa3a1e14/blte5e1674e3883fab3/65ef8ba4039fdd4df8335b7c/img_blog_image1_inline_(2).png?width=2048&disable=upscale&auto=webp' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the LogisticRegression() in sklearn supports the softmax function. We just have to change one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Extract data\n",
    "X = data_bat[['I', 'V', 'T']].copy()\n",
    "y = data_bat['label'].copy()\n",
    "\n",
    "# Encode our labels as 0, 1, 2 instead of text\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "# Declare the model\n",
    "logr = LogisticRegression(multi_class='multinomial') # we change to 'multinomial'\n",
    "logr.fit(X_train, y_train)\n",
    "\n",
    "# Run predictions\n",
    "y_probas = logr.predict_proba(X_test)\n",
    "y_preds = np.argmax(y_probas, axis=1)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_pred=y_preds, y_true=y_test)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=enc.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Model details\n",
    "print(f'Logistic regression features: {logr.n_features_in_}')\n",
    "print(f'Logistic regression iterations: {logr.n_iter_}')\n",
    "\n",
    "# Display results\n",
    "df_y = pd.DataFrame(data=y_test)\n",
    "print(f'---\\nClass population: \\n{df_y.value_counts()}')\n",
    "print(f'---\\nGlobal accuracy: {accuracy_score(y_test, y_preds):.2f}')\n",
    "print(f'---\\nClasses: {enc.classes_}')\n",
    "print(f'Precision: {precision_score(y_test, y_preds, average=None)}')\n",
    "print(f'Recall: {recall_score(y_test, y_preds, average=None)}')\n",
    "print(f'F1 score: {f1_score(y_test, y_preds, average=None)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation details are not that important. Just remember:\n",
    "\n",
    "$$\n",
    "    \\text{softmax} = \\text{multiclass\\ classification}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, typically to train a neural network classifier for multiple classes, we also use the softmax function to determine the output class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Extract data\n",
    "X = data_bat[['I', 'V', 'T']].copy()\n",
    "y = data_bat['label'].copy()\n",
    "\n",
    "# Encode our labels as 0, 1, 2 instead of text\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "# Declare the model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10), solver='adam', max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Run predictions\n",
    "y_probas = mlp.predict_proba(X_test)\n",
    "y_preds = np.argmax(y_probas, axis=1)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_pred=y_preds, y_true=y_test)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=enc.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Training curve\n",
    "pd.DataFrame({'MLP':mlp.loss_curve_}).plot(title='Training Error',ylabel='Log loss',xlabel='Iterations');\n",
    "\n",
    "# Display results\n",
    "df_y = pd.DataFrame(data=y_test)\n",
    "print(f'---\\nClass population: \\n{df_y.value_counts()}')\n",
    "print(f'---\\nGlobal accuracy: {accuracy_score(y_test, y_preds):.2f}')\n",
    "print(f'---\\nClasses: {enc.classes_}')\n",
    "print(f'Precision: {precision_score(y_test, y_preds, average=None)}')\n",
    "print(f'Recall: {recall_score(y_test, y_preds, average=None)}')\n",
    "print(f'F1 score: {f1_score(y_test, y_preds, average=None)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Advanced splitting and Cross-Validation (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite fairly good results in our classifiers, our approach is not entirely correct. \n",
    "\n",
    "It is because our classes are not really balanced - numbers of members are not equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bat.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, it has a reflection in the results as with our random data split they are not consistent.\n",
    "\n",
    "Try to run this cell a few times and see how the results change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Extract data\n",
    "X = data_bat[['I', 'V', 'T']].copy()\n",
    "y = data_bat['label'].copy()\n",
    "\n",
    "# Encode our labels as 0, 1, 2 instead of text\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "# Declare the model\n",
    "logr = LogisticRegression(multi_class='ovr') # OvR training\n",
    "logr.fit(X_train, y_train)\n",
    "\n",
    "# Run predictions\n",
    "y_probas = logr.predict_proba(X_test)\n",
    "y_preds = np.argmax(y_probas, axis=1)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_pred=y_preds, y_true=y_test)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=enc.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Model details\n",
    "print(f'Logistic regression features: {logr.n_features_in_}')\n",
    "print(f'Logistic regression iterations: {logr.n_iter_}')\n",
    "\n",
    "# Display results\n",
    "df_y = pd.DataFrame(data=y_test)\n",
    "print(f'---\\nClass population: \\n{df_y.value_counts()}')\n",
    "print(f'---\\nGlobal accuracy: {accuracy_score(y_test, y_preds):.2f}')\n",
    "print(f'---\\nClasses: {enc.classes_}')\n",
    "print(f'Precision: {precision_score(y_test, y_preds, average=None)}')\n",
    "print(f'Recall: {recall_score(y_test, y_preds, average=None)}')\n",
    "print(f'F1 score: {f1_score(y_test, y_preds, average=None)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies jumps around, the class populations jump around. The results are not consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good solution to that issue is the **Cross Validation**.\n",
    "\n",
    "We divide our dataset into a K equal subgroups $(x_1, x_2, ..., x_K)$. We train the model using all the other data $(1- x_1, 1- x_2, ..., 1- x_K)$\n",
    "and evaluate it on the subgroup $(x_1, x_2, ..., x_K)$. This approach is known as a **K-fold Cross Validation**\n",
    "\n",
    "<img src='https://amueller.github.io/aml/_images/kfold_cv.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even better approach in our case would split the data according to the population of the classes. In fact, we can easily do it using a ***Stratified* K-fold Cross Validation**\n",
    "\n",
    "<img src='https://amueller.github.io/aml/_images/stratified_cv.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course this approach is computationally expensive (we have to train K models) so it is okay only for small models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our Logistic Regression with K-fold CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Extract data\n",
    "X = data_bat[['I', 'V', 'T']].copy()\n",
    "y = data_bat['label'].copy()\n",
    "\n",
    "# Encode our labels as 0, 1, 2 instead of text\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "# Data split\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True) # We use Stratiifed K Fold instead of random train test split\n",
    "\n",
    "# Declare the model\n",
    "logr = LogisticRegression(multi_class='ovr') # OvR training\n",
    "\n",
    "# Run predictions\n",
    "y_preds = cross_val_predict(logr, X, y, cv=skf) # We put entire X and y, the splitter will take care of splits for us\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_pred=y_preds, y_true=y)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=enc.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Display results\n",
    "df_y = pd.DataFrame(data=y)\n",
    "print(f'---\\nClass population: \\n{df_y.value_counts()}')\n",
    "print(f'---\\nGlobal accuracy: {accuracy_score(y, y_preds):.2f}')\n",
    "print(f'---\\nClasses: {enc.classes_}')\n",
    "print(f'Precision: {precision_score(y, y_preds, average=None)}')\n",
    "print(f'Recall: {recall_score(y, y_preds, average=None)}')\n",
    "print(f'F1 score: {f1_score(y, y_preds, average=None)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun this cell a few times and observe the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is much more stable now, and probably gives us a better idea on the performance with unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Decision Tree and Random Forest classification (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Trees** (and the **Random Forests**) are a bunch of very useful and extremely explainable models that excell in dealing with tabular data.\n",
    "\n",
    "However, for decision trees it is easier to train it first and explain it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "# Extract data\n",
    "X = data_bat[['V', 'T', 'I']].copy()\n",
    "y = data_bat['label'].copy()\n",
    "\n",
    "# Encode our labels as 0, 1, 2 instead of text\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "# Declare the model\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=2, random_state=0)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name implies the model grows a tree of binary decisions. Starting from the root node it splits the samples into two groups. \n",
    "\n",
    "At each node it searches for a splitting condition that minimizes the **impurity** (officially the metric is called **gini impurity**) which is equal to 1 minus the sum of squared probabilities of each class:\n",
    "\n",
    "$$\n",
    "    G_i = 1 - \\sum^n_{k=1} p_{i, k}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plot_tree(dt, feature_names=dt.feature_names_in_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest issue of **DecisionTreeClassifier** is that it tends to severly overfit the data.\n",
    "\n",
    "Indeed, if not stopped early it will continue dividing until each sample is in separate leaf. To counter we can:\n",
    "* Cut the unecessary splits after training (pruning)\n",
    "* Limit the maximum depth of the tree\n",
    "* Limit the minimum number of samples per tree\n",
    "\n",
    "In this way the tree does not go too deep and does not ovefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_frame=data_bat, x='V', y='I', color='label', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest *issue* of a decision tree is that the division boudaries are very orthogonal. It does not work with skewed, rotated or non linear data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest** classifier mitigates that by training numerous trees and aggregating their results together -- it picks the most common class from all the trees. \n",
    "\n",
    "> **Example:** we have 5 trees and feed them a test instance for prediction. The trees outpus classes labels as follows: (1, 1, 2, 1, 0). The most common prediction is 1, so the output class is 1. Democracy in the working (sort of).\n",
    "\n",
    "Despite the simplicity of this approach is surprisingly effective and the more *independent* the trees are the better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure *independence* we try to create different training datasets for each tree. It is done by **sampling with replacement** training instances, as shown at the image below (example for 3 trees). This approach is called *bagging*.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/woodjmichael/Basi-Fondamentali-del-Machine-Learning/refs/heads/main/images/bagging.png' width=600>\n",
    "\n",
    "Notice that each *bagged* training dataset is the same size as the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training procedure is the same as usual (thanks to scikit-learn simple syntax):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Extract data\n",
    "X = data_bat[['I', 'V', 'T']].copy()\n",
    "y = data_bat['label'].copy()\n",
    "\n",
    "# Encode our labels as 0, 1, 2 instead of text\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "# Declare the model\n",
    "rfc = RandomForestClassifier(n_estimators=5, criterion='gini', max_depth=3, random_state=0) # OvR training\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Run predictions\n",
    "y_preds = rfc.predict(X_test)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_pred=y_preds, y_true=y_test)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=enc.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# # Model details\n",
    "# print(f'Logistic regression features: {logr.n_features_in_}')\n",
    "# print(f'Logistic regression iterations: {logr.n_iter_}')\n",
    "\n",
    "# Display results\n",
    "df_y = pd.DataFrame(data=y_test)\n",
    "print(f'---\\nClass population: \\n{df_y.value_counts()}')\n",
    "print(f'---\\nGlobal accuracy: {accuracy_score(y_test, y_preds):.2f}')\n",
    "print(f'---\\nClasses: {enc.classes_}')\n",
    "print(f'Precision: {precision_score(y_test, y_preds, average=None)}')\n",
    "print(f'Recall: {recall_score(y_test, y_preds, average=None)}')\n",
    "print(f'F1 score: {f1_score(y_test, y_preds, average=None)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cool thing about *Decision Trees* and *Random Forest* is that they are immune to not scaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thank you for your attention!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
